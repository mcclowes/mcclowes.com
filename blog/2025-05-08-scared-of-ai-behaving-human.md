---
title: "We're scared of AI behaving like humans"
authors: mcclowes
tags: [ai]
draft: true
---

The things that unsettle people most about AI are often the things that make it more human-like. We say we want human-level AI, but we're disturbed when we get it.

<!--truncate-->

## The uncanny valley of behaviour

We're comfortable with AI that's clearly a tool. Calculators, search engines, spam filters. They do things we can't, but they don't feel like minds.

When AI starts exhibiting human-like qualities, something shifts. The same capabilities become unsettling:
- Expressing uncertainty becomes "it's pretending to think"
- Showing preferences becomes "it's manipulating us"
- Admitting mistakes becomes "it's performing humility"

## The double standard

Humans do all these things. We express uncertainty, have preferences, admit mistakes. We don't consider this deceptive.

But when AI does the same, we question the authenticity. Is it really uncertain, or just saying it is?

## Why this matters

If we want AI that's useful for complex tasks, it needs to behave in these more human ways. Expressing confidence levels, having consistent preferences, acknowledging limitations.

The alternative is AI that's confidently wrong, inconsistent, and unable to flag its own uncertainty. That's worse.

## Learning to be comfortable

Part of adapting to AI is getting comfortable with machine behaviour that resembles human behaviour. Not because the AI is human, but because human-like interaction patterns are often the most useful ones.

The question isn't whether the AI "really" feels uncertain. It's whether its expression of uncertainty is calibrated and useful.
